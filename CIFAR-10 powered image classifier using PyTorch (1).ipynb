{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Import relevant pytorch libraries for the process\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torch.utils.data\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Gather the relevant dataset from torch vision in order to train and test the built model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.4914, 0.48216, 0.44653)\n",
    "                                                                           ,(0.24703, 0.24349, 0.26159))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,download=True, transform=transform)\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True, transform=transform)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=100,shuffle=True, num_workers=0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100,shuffle=False, num_workers=0)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Build the model with 3 layers including 1 hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(32*32*3, 500) #the size of a single data entry as input layer units\n",
    "        self.fc2 = nn.Linear(500, 10) #a hidden layer and a 10 class output\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x)) #activation function ReLU used to cater non-linearity\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: Train the model using the CIFAR-10 dataset as downloaded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()   #create an object of class Net\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4) #gradient descent optimizing function with tuned learning rate\n",
    "criterion = nn.CrossEntropyLoss() #classification loss function\n",
    "\n",
    "for iterations in range(10): \n",
    "    for batch_id, data_target in enumerate(trainloader):\n",
    "      inputdata = data_target[0] #image\n",
    "      target = data_target[1] #label of the data entry in the batch\n",
    "      inputdata = inputdata.view(-1, 32 * 32 * 3) #convert incoming images to vectors\n",
    "      optimizer.zero_grad() # so gradients from previous iterations are equated to zero for new iteration\n",
    "\n",
    "      # Complete a forward pass\n",
    "      output = model(inputdata)\n",
    "\n",
    "      # Compute the loss, gradients and change the weights\n",
    "      loss = criterion(output,target)\n",
    "      loss.backward() #compute new gradients\n",
    "      optimizer.step() #adjust the weights\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5: Test/Evaluate the model with the loaded test dataset from CIFAR-10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The testing set accuracy of the network is: 52 %\n"
     ]
    }
   ],
   "source": [
    "# Set the model in evaluation mode\n",
    "model.eval() \n",
    "correct, total = 0, 0\n",
    "predictions = []\n",
    "\n",
    "for i, data in enumerate(testloader, 0):\n",
    "      inputs, labels = data\n",
    "    \n",
    "      # Put each image into a vector\n",
    "      inputs = inputs.view(-1, 32*32*3)\n",
    "    \n",
    "      # Do the forward pass and get the predictions\n",
    "      outputs = model(inputs)\n",
    "      _, outputs = torch.max(outputs.data,1)\n",
    "      total += labels.size(0)\n",
    "      correct += (outputs == labels).sum().item()\n",
    "print('The testing set accuracy of the network is: %d %%' % (100 * correct / total))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
